# -*- coding: utf-8 -*-
"""House price advanced regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQCz9LP81YIppDw2KKrj7GEfv8UkJIMT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import  mean_squared_error

import lightgbm as lgb
import xgboost as xgb

train = pd.read_csv('/content/train (3).csv')
test = pd.read_csv('/content/test (4).csv')

print(f"Train shape: {train.shape}\nTest shape: {test.shape}")
pd.set_option('display.max_columns', None)
print(train.describe().T)
num_cols = train.select_dtypes(exclude='object').columns
cat_cols = train.select_dtypes(include='object').columns
print('Numerical columns:', num_cols, '\nNumber:', len(num_cols))
print('='*40)
print('Categorical columns:', cat_cols, '\nNumber:', len(cat_cols))

plt.figure(figsize=(15, 10))
mask = np.triu(np.ones_like(train[num_cols].corr(), dtype=bool))
sns.heatmap(train[num_cols].corr(), mask=mask, annot=True, cmap='Greens', fmt=".1f")
plt.title("Correlation Matrix")
plt.tight_layout()
plt.show()

train_ids = train['Id']
test_ids = test['Id']
train_target = train['SalePrice']
train_features = train.drop(['Id', 'SalePrice'], axis=1)
test_features = test.drop('Id', axis=1)

combine_data = pd.concat([train_features, test_features], axis=0, ignore_index=True)

cols_with_miss = [col for col in combine_data.columns if combine_data[col].isnull().any()]
miss_val_df = pd.DataFrame(combine_data[cols_with_miss].isna().sum(), columns=['Miss value'])
print(miss_val_df)

missing_none = [
    'Alley','PoolQC', 'MiscFeature', 'Fence','FireplaceQu',
    'GarageType','GarageFinish','GarageQual','GarageCond',
    'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1',
    'BsmtFinType2','MasVnrType'
]
for col in missing_none:
    combine_data[col] = combine_data[col].fillna('None')

cat_cols_all = combine_data.select_dtypes(include='object').columns
num_cols_all = combine_data.select_dtypes(exclude='object').columns
for col in cat_cols_all:
    combine_data[col] = combine_data[col].fillna(combine_data[col].mode()[0])
for col in num_cols_all:
    combine_data[col] = combine_data[col].fillna(combine_data[col].median())

for col in cat_cols_all:
    le = LabelEncoder()
    combine_data[col] = le.fit_transform(combine_data[col])

processed_train = combine_data.iloc[:train.shape[0]]
processed_test = combine_data.iloc[train.shape[0]:]
print(f"Processed train shape: {processed_train.shape}")
print(f"Processed test shape: {processed_test.shape}")

X_train, X_test, y_train, y_test = train_test_split(processed_train, train_target, test_size=0.2, random_state=42)



lgb_params = {
    'objective': 'regression_l1',
    'metric': 'rmse',
    'n_estimators': 10000,
    'n_jobs': -1,
    'learning_rate': 0.005,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 1,
    'min_child_samples': 20,
    'verbose': -1,
    'seed': 42,
    'boosting_type': 'gbdt',
}

model_lgb = lgb.LGBMRegressor(**lgb_params)
model_lgb.fit(X_train, y_train,
              eval_set=[(X_test, y_test)],
              eval_metric='rmse',
              callbacks=[lgb.early_stopping(100, verbose=False)])

y_pred_lgb = model_lgb.predict(X_test)
mse_lgb = mean_squared_error(y_test, y_pred_lgb)
print(f"Mean Squared Error (LightGBM): {mse_lgb}")

test_predictions_lgb = model_lgb.predict(processed_test)
submission_lgb = pd.DataFrame({'Id': test_ids, 'SalePrice': test_predictions_lgb})
submission_lgb.to_csv('submission_lgb.csv', index=False)
print("Submission file 'submission_lgb.csv' created successfully!")

import xgboost as xgb

xgb_params = {
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'n_estimators': 10000,
    'learning_rate': 0.005,
    'max_depth': 5,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'seed': 42,
    'n_jobs': -1,
}

model_xgb = xgb.XGBRegressor(**xgb_params)

model_xgb.fit(X_train, y_train,
              eval_set=[(X_test, y_test)],
              verbose=False)

test_predictions_xgb = model_xgb.predict(processed_test)
submission_xgb = pd.DataFrame({'Id': test_ids, 'SalePrice': test_predictions_xgb})
submission_xgb.to_csv('submission_xgb.csv', index=False)
print("Submission file 'submission_xgb.csv' created successfully!")